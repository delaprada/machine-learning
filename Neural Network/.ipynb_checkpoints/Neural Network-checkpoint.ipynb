{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e9f4245",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'to_string'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1f/267vc31d7rsb8b7m9jhtv_6h0000gn/T/ipykernel_85507/2563200261.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_learning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_feature_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0mplot_the_loss_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/1f/267vc31d7rsb8b7m9jhtv_6h0000gn/T/ipykernel_85507/2563200261.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataset, epochs, label_name, batch_size)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'generator' object has no attribute 'to_string'"
     ]
    }
   ],
   "source": [
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "import tensorflow as tf;\n",
    "from tensorflow.keras import layers;\n",
    "from matplotlib import pyplot as plt;\n",
    "import seaborn as sns;\n",
    "\n",
    "pd.options.display.max_rows = 10;\n",
    "pd.options.display.float_format = \"{:.1f}\".format;\n",
    "\n",
    "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
    "train_df = train_df.reindex(np.random.permutation(train_df.index)) # shuffle the examples\n",
    "test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")\n",
    "\n",
    "# normalize\n",
    "train_df_mean = train_df.mean();\n",
    "train_df_std = train_df.std();\n",
    "train_df_norm = (train_df - train_df_mean) / train_df_std;\n",
    "\n",
    "test_df_mean = test_df.mean();\n",
    "test_df_std = test_df.std();\n",
    "test_df_norm = (test_df - test_df_mean) / test_df_std;\n",
    "\n",
    "# 创建一个空数组，用于放置所有新创建的 feature columns\n",
    "feature_columns = [];\n",
    "\n",
    "resolution_in_Zs = 0.3; # 以 0.3 作为 bucket 的间隔\n",
    "\n",
    "latitude_as_a_numeric_column = tf.feature_column.numeric_column('latitude'); # 创建新的 feature_column\n",
    "latitude_boundaries = list(np.arange(\n",
    "    int(min(train_df_norm['latitude'])),\n",
    "    int(max(train_df_norm['latitude'])),\n",
    "    resolution_in_Zs)); # 根据 latitude 取值范围的最大值、最小值、bucket 间隔划分 latitude 的 boundaries\n",
    "latitude = tf.feature_column.bucketized_column(latitude_as_a_numeric_column, latitude_boundaries); # bucketize 之后的 feature_column\n",
    "\n",
    "longitude_as_a_numeric_column = tf.feature_column.numeric_column('longitude'); # 创建新的 feature_column\n",
    "longitude_boundaries = list(np.arange(\n",
    "    int(min(train_df_norm['longitude'])),\n",
    "    int(max(train_df_norm['longitude'])),\n",
    "    resolution_in_Zs)); # 根据 latitude 取值范围的最大值、最小值、bucket 间隔划分 latitude 的 boundaries\n",
    "longitude = tf.feature_column.bucketized_column(longitude_as_a_numeric_column, longitude_boundaries); # bucketize 之后的 feature_column\n",
    "\n",
    "# 创建基于 latitude 和 longitude 的 feature cross\n",
    "latitude_x_longitude = tf.feature_column.crossed_column([latitude, longitude], hash_bucket_size = 100);\n",
    "crossed_feature = tf.feature_column.indicator_column(latitude_x_longitude);\n",
    "feature_columns.append(crossed_feature);\n",
    "\n",
    "median_income = tf.feature_column.numeric_column('median_income');\n",
    "feature_columns.append(median_income);\n",
    "\n",
    "population = tf.feature_column.numeric_column('population');\n",
    "feature_columns.append(population);\n",
    "\n",
    "# Convert the list of feature columns into a layer that will later be fed into\n",
    "# the model. \n",
    "my_feature_layer = tf.keras.layers.DenseFeatures(feature_columns);\n",
    "\n",
    "# 画出 loss vs. epoch 图\n",
    "def plot_the_loss_curve(epochs, mse):\n",
    "    plt.figure();\n",
    "    plt.xlabel('Epoch');\n",
    "    plt.ylabel('Mean Square Error');\n",
    "    \n",
    "    plt.plot(epochs, mse, label = 'Loss');\n",
    "    plt.legend();\n",
    "    \n",
    "    plt.ylim([mse.min()*0.95, mse.max()*1.03]);\n",
    "    plt.show();\n",
    "\n",
    "\n",
    "# 创建 Neural Network Model\n",
    "def create_model(my_learning_rate, my_feature_layer):\n",
    "    model = tf.keras.models.Sequential();\n",
    "\n",
    "    model.add(my_feature_layer);\n",
    "    \n",
    "    # 第一隐层有 20 个 neuron，激活函数为 relu\n",
    "    model.add(tf.keras.layers.Dense(units = 20,\n",
    "                                    activation = 'relu',\n",
    "                                    kernel_regularizer = tf.keras.regularizers.l2(l=0.01),\n",
    "                                    name = 'Hidden1'));\n",
    "    \n",
    "    # 定义 dropout 层，用于避免过拟合，增强泛化能力\n",
    "    model.add(tf.keras.layers.Dropout(rate = 0.25));\n",
    "    \n",
    "    \n",
    "    # 第二隐层有 12 个 neuron，激活函数为 relu\n",
    "    model.add(tf.keras.layers.Dense(units = 12,\n",
    "                                    activation = 'relu',\n",
    "                                    kernel_regularizer = tf.keras.regularizers.l2(l=0.01),\n",
    "                                    name = 'Hidden2'));\n",
    "    \n",
    "    # 确定输出层\n",
    "    model.add(tf.keras.layers.Dense(units = 1, name = 'Output'));\n",
    "    \n",
    "    # 设置模型训练过程使用的梯度下降方法、learning rate，metrics\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr = my_learning_rate),\n",
    "                  loss = 'mean_squared_error',\n",
    "                  metrics = [tf.keras.metrics.MeanSquaredError()]);\n",
    "    \n",
    "    return model;\n",
    "\n",
    "# 训练模型\n",
    "def train_model(model, dataset, epochs, label_name, batch_size = None):\n",
    "    features = {name: np.array(value) for name, value in dataset.items()};\n",
    "    \n",
    "    for name, value in dataset.items():\n",
    "        print(f'name: {name}');\n",
    "        print(f'value: {value}');\n",
    "    \n",
    "    label = np.array(features.pop(label_name));\n",
    "    \n",
    "    history = model.fit(x = features, y = label, epochs = epochs, batch_size = batch_size, shuffle = True);\n",
    "    \n",
    "    epochs = history.epoch;\n",
    "    \n",
    "    hist = pd.DataFrame(history.history);\n",
    "    \n",
    "    mse = hist['mean_squared_error'];\n",
    "    \n",
    "    return epochs, mse;\n",
    "\n",
    "my_learning_rate = 0.01;\n",
    "epochs = 10;\n",
    "batch_size = 1000;\n",
    "\n",
    "label_name = 'median_house_value';\n",
    "\n",
    "my_model = create_model(my_learning_rate, my_feature_layer);\n",
    "\n",
    "epochs, mse = train_model(my_model, train_df_norm, epochs, label_name, batch_size);\n",
    "\n",
    "plot_the_loss_curve(epochs, mse);\n",
    "\n",
    "\n",
    "# 检测在测试集的表现\n",
    "test_features = {name: np.array(value) for name, value in test_df_norm.items()};\n",
    "test_label = np.array(test_features.pop(label_name));\n",
    "my_model.evaluate(x = test_features, y = test_label, batch_size = batch_size);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9213e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
